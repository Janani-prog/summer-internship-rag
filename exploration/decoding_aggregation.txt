J = Create_Empty_List()
P_k = Retrieve_Passages_For_Query(q)

For each passage p_j in P_k:
        prob_of_dont_know = LLM.Get_Probability_Of_Saying_IDK(query=q, passage=p_j) //of you only had this passage to generate response, whats the probability of saying 'I don't know?' 

        If prob_of_dont_know < gamma:
            Add p_j to J

If J is Empty:
    Return "I don't know" 

// Additional filtering

// 1. Passage Re-ranking
re_ranked_J = Create_Empty_List()
passage_scores = {}
For each passage p_j in J:
    passage_scores[p_j] = ReRanker_Model.Score(query=q, passage=p_j) //cross encoder

sorted_passages = Sort_By_Score_Descending(passage_scores)
J = Select_Top_N_Passages(sorted_passages, N) 

// 2. Factual Consistency 
filtered_J_by_consistency = Create_Empty_List()
For each passage p_j in J:
    is_consistent = LLM.Check_Consistency(statement=p_j.content, known_facts_or_other_reliable_sources_or_other_passages=J_minus_pj)
    If is_consistent:
        Add p_j to filtered_J_by_consistency
J = filtered_J_by_consistency

    
r_star = Create_Empty_String()

For current_token_index from 1 to T_max:

    v_j_vectors = Create_Empty_List()
    For each passage p_j in J:
        v_j = LLM.Get_Next_Token_Probability_Vector(query=q, passage=p_j, current_answer_prefix=r_star) //from original query, specific passage and what has been generated already
        Add v_j to all_v_j_vectors

    v_hat = Perform_Element_Wise_Average(all_v_j_vectors)

    (token_1, prob_1), (token_2, prob_2) = Get_Top_Two_Tokens_And_Probs(v_hat)

    confidence_gap = prob_1 - prob_2

    If confidence_gap > eta:
        t_star = token_1
    Else:
        t_star = LLM.Get_Next_Token_Without_Passages()

    r_star = r_star + t_star
e